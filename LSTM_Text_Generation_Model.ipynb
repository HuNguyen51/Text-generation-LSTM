{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PifG83Hk6mVW"
      },
      "source": [
        "# Import module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "s7aphLVu6mVY"
      },
      "outputs": [],
      "source": [
        "#from transformers import AutoTokenizer\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "O8gBzo966mVZ"
      },
      "outputs": [],
      "source": [
        "# Chúng ta có thể sử dụng phobert để tokenize chữ tiếng Việt với bộ từ điển lớn hơn\n",
        "#tokenizer = AutoTokenizer.from_pretrained('vinai/phobert-base')\n",
        "# Tất nhiên khi sử dụng tokenizer trên bộ từ điển của mình thì sẽ có thể gặp trường hợp bị thiếu từ và có thể sẽ bị lỗi khi hiện thực (vì chữ trong input không có trong tokenizer của mình)\n",
        "# Nên để sử dụng được cho nhiều trường hợp thì ta nên dùng phobert đã train sẵn và sử dụng với bộ từ điển lớn và chính xác hơn\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\]^`{|}~ ') # không để dấu gạch dưới _"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aEEtY4p6mVa"
      },
      "source": [
        "# Load file đã Tiền xử lý"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5Hk0mi0A6mVa"
      },
      "outputs": [],
      "source": [
        "# Đọc dữ liệu từ file train.txt được tạo sau khi đã tiền xử lý dữ liệu\n",
        "sequences = []\n",
        "with open('train.txt', 'r', encoding='utf-16') as f:\n",
        "    for line in f.readlines():\n",
        "        sequences.append(line.strip()) # do khi đọc file sẽ có dấu \\n và hàm strip sẽ bỏ nó đi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RW0dnQEH6mVa"
      },
      "outputs": [],
      "source": [
        "# Hàm fit_on_texts dùng để chuyển các từ thành số như một bảng ánh xạ (vì model chỉ tính toán trên những con số)\n",
        "tokenizer.fit_on_texts(sequences)\n",
        "# Lưu tokenizer lại để sử dụng cho việc hiện thực hóa model\n",
        "with open('tokenizer.pkl', 'wb') as f:\n",
        "  pickle.dump(tokenizer, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zL7bV9Y36mVb"
      },
      "outputs": [],
      "source": [
        "# sau khi fit_on_texts, ta tiến hành chuyển nó thành số dựa trên bảng đã tạo\n",
        "sequences_digit = tokenizer.texts_to_sequences(sequences)\n",
        "sequences_digit = np.array(sequences_digit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-3BB-qh6mVb",
        "outputId": "bb258663-1dc4-40b1-ff29-bff70cc41151"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((305461, 50), (305461,))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "# Lấy đầu vào và đầu ra phù hợp với model\n",
        "X, y = sequences_digit[:, :-1], sequences_digit[:,-1]\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZHQUsII6mVc"
      },
      "source": [
        "# Xây dựng model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8HZwOdfN6mVc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAvRrdW16mVc",
        "outputId": "561a72dd-e3a8-4e8e-b210-4ab6e0602edb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 50, 64)            931520    \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 50, 64)           256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 50, 512)          657408    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 512)              1574912   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 14555)             7466715   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,895,515\n",
            "Trainable params: 10,894,363\n",
            "Non-trainable params: 1,152\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Khởi tạo model RNN\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Embedding(vocab_size, 64, input_length=X.shape[1]),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Bidirectional(layers.LSTM(256, return_sequences=True)),\n",
        "    layers.Bidirectional(layers.LSTM(256, return_sequences=False)),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5AhRWPS6mVc",
        "outputId": "cfc100f9-85ba-4a3e-fed2-9be4fd0d1ff2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1194/1194 [==============================] - 171s 107ms/step - loss: 6.0153 - accuracy: 0.1061\n",
            "Epoch 2/20\n",
            "1194/1194 [==============================] - 98s 82ms/step - loss: 5.4419 - accuracy: 0.1329\n",
            "Epoch 3/20\n",
            "1194/1194 [==============================] - 96s 80ms/step - loss: 5.0129 - accuracy: 0.1571\n",
            "Epoch 4/20\n",
            "1194/1194 [==============================] - 94s 79ms/step - loss: 4.6339 - accuracy: 0.1817\n",
            "Epoch 5/20\n",
            "1194/1194 [==============================] - 94s 78ms/step - loss: 4.2857 - accuracy: 0.2098\n",
            "Epoch 6/20\n",
            "1194/1194 [==============================] - 93s 78ms/step - loss: 3.9686 - accuracy: 0.2399\n",
            "Epoch 7/20\n",
            "1194/1194 [==============================] - 94s 79ms/step - loss: 3.6722 - accuracy: 0.2722\n",
            "Epoch 8/20\n",
            "1194/1194 [==============================] - 92s 77ms/step - loss: 3.4053 - accuracy: 0.3048\n",
            "Epoch 9/20\n",
            "1194/1194 [==============================] - 92s 77ms/step - loss: 3.1601 - accuracy: 0.3365\n",
            "Epoch 10/20\n",
            "1194/1194 [==============================] - 92s 77ms/step - loss: 2.9465 - accuracy: 0.3671\n",
            "Epoch 11/20\n",
            "1194/1194 [==============================] - 92s 77ms/step - loss: 2.7470 - accuracy: 0.3965\n",
            "Epoch 12/20\n",
            "1194/1194 [==============================] - 92s 77ms/step - loss: 2.5797 - accuracy: 0.4214\n",
            "Epoch 13/20\n",
            "1194/1194 [==============================] - 92s 77ms/step - loss: 2.4216 - accuracy: 0.4450\n",
            "Epoch 14/20\n",
            "1194/1194 [==============================] - 91s 77ms/step - loss: 2.2813 - accuracy: 0.4691\n",
            "Epoch 15/20\n",
            "1194/1194 [==============================] - 93s 78ms/step - loss: 2.1516 - accuracy: 0.4899\n",
            "Epoch 16/20\n",
            "1194/1194 [==============================] - 92s 77ms/step - loss: 2.0419 - accuracy: 0.5086\n",
            "Epoch 17/20\n",
            "1194/1194 [==============================] - 91s 76ms/step - loss: 1.9338 - accuracy: 0.5283\n",
            "Epoch 18/20\n",
            "1194/1194 [==============================] - 91s 77ms/step - loss: 1.8374 - accuracy: 0.5449\n",
            "Epoch 19/20\n",
            "1194/1194 [==============================] - 91s 77ms/step - loss: 1.7581 - accuracy: 0.5602\n",
            "Epoch 20/20\n",
            "1194/1194 [==============================] - 91s 77ms/step - loss: 1.6769 - accuracy: 0.5751\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f464052bb80>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tiến hành huấn luyện model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=20, batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5z9PfAHx6mVd",
        "outputId": "c75102d2-9bea-42ac-c48a-d2eb8dff0568"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1194/1194 [==============================] - 90s 76ms/step - loss: 1.1241 - accuracy: 0.6901\n",
            "Epoch 2/10\n",
            "1194/1194 [==============================] - 92s 77ms/step - loss: 1.0902 - accuracy: 0.6969\n",
            "Epoch 3/10\n",
            "1194/1194 [==============================] - 92s 77ms/step - loss: 1.0546 - accuracy: 0.7069\n",
            "Epoch 4/10\n",
            "1194/1194 [==============================] - 92s 77ms/step - loss: 1.0282 - accuracy: 0.7126\n",
            "Epoch 5/10\n",
            "1194/1194 [==============================] - 92s 77ms/step - loss: 1.0046 - accuracy: 0.7179\n",
            "Epoch 6/10\n",
            "1194/1194 [==============================] - 92s 77ms/step - loss: 0.9793 - accuracy: 0.7233\n",
            "Epoch 7/10\n",
            "1194/1194 [==============================] - 92s 77ms/step - loss: 0.9556 - accuracy: 0.7296\n",
            "Epoch 8/10\n",
            "1194/1194 [==============================] - 92s 77ms/step - loss: 0.9308 - accuracy: 0.7354\n",
            "Epoch 9/10\n",
            "1194/1194 [==============================] - 92s 77ms/step - loss: 0.9068 - accuracy: 0.7415\n",
            "Epoch 10/10\n",
            "1194/1194 [==============================] - 92s 77ms/step - loss: 0.8894 - accuracy: 0.7456\n"
          ]
        }
      ],
      "source": [
        "# Huấn luyện thêm có thể chạy bao nhiêu lần tùy thích (để đạt được accuracy: 0.7456 mình đã chạy khoảng 70 epoch nhé!)\n",
        "model.fit(X, y, epochs=10, batch_size=256)\n",
        "model.save('weight_lstm_model.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
