{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyvi import ViTokenizer\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOKBACK_LENGTH = 50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Làm sạch đầu vào"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tôi', 'là', 'sinh_viên']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "def make_clean(string, to_tokens=True):\n",
    "    res = string.lower()\n",
    "    res = remove_emoji(res)\n",
    "    res = re.sub(r'[!“”\"#$%&\\()*+,-./:;<=>?@[\\]^_`{|}~]', \" \", res)\n",
    "    res = re.sub(r'\\s+', ' ', res).strip()\n",
    "    res = ViTokenizer.tokenize(res)\n",
    "    if to_tokens:\n",
    "        res = res.split()\n",
    "    return res\n",
    "\n",
    "make_clean('Tôi     là(*(*%$sinh (*&viên', to_tokens=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hiện thực hóa model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "with open('tokenizer.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "# load weight model lstm\n",
    "model = load_model('weight_lstm_model.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input đầu vào\n",
    "text = 'TPHCM đào tạo đại học cho người sau cai nghiện Đại học Mở-Bán công đã khai giảng lớp đại học từ xa khoa Xã hội và Nhân văn đầu tiên cho học viên, người sau cai nghiện và một số cán bộ, công nhân viên các trung tâm giáo dục dạy nghề của thành phố. Lớp học, được đào tạo theo chế độ tín chỉ, gồm 169 sinh viên, trong đó có 47 học viên sau cai nghiện. Các sinh viên sẽ học tập trung mỗi tuần 2 ngày, thời gian còn lại là tự nghiên cứu. Các học viên sau khi tốt nghiệp đại học sẽ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input(text):\n",
    "    # làm sạch đầu vào\n",
    "    clean_text = make_clean(text, to_tokens=True)\n",
    "    # lấy ra 50 từ cuối \n",
    "    last_seq = [clean_text[-50:]]\n",
    "    # chuyển 50 từ cuối đó thành số\n",
    "    tokens = tokenizer.texts_to_sequences(last_seq)\n",
    "    seq_len = len(tokens[0])\n",
    "    pad_len = [0 for _ in range(LOOKBACK_LENGTH-seq_len)]\n",
    "    return [pad_len + tokens[0]]\n",
    "\n",
    "def predict_class(text): # text đã qua tiền xử lý\n",
    "    text_pred = model.predict(text, verbose=None) \n",
    "    return np.argmax(text_pred, axis=1)\n",
    "\n",
    "# tạo các từ tiếp theo dựa trên input đầu vào\n",
    "def generate(text, generate_len=15): # 15 từ sẽ được tạo \n",
    "    print('text input:', text)\n",
    "    text = process_input(text)\n",
    "    predict_seq = []\n",
    "    for _ in range(generate_len):\n",
    "        pred = predict_class(text)\n",
    "        predict_seq.append(pred[0])\n",
    "        text = np.concatenate([text, [pred]], axis=1)[:,1:]\n",
    "    print('text generated:', tokenizer.sequences_to_texts([predict_seq])[0].replace('_', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text input: TPHCM đào tạo đại học cho người sau cai nghiện Đại học Mở-Bán công đã khai giảng lớp đại học từ xa khoa Xã hội và Nhân văn đầu tiên cho học viên, người sau cai nghiện và một số cán bộ, công nhân viên các trung tâm giáo dục dạy nghề của thành phố. Lớp học, được đào tạo theo chế độ tín chỉ, gồm 169 sinh viên, trong đó có 47 học viên sau cai nghiện. Các sinh viên sẽ học tập trung mỗi tuần 2 ngày, thời gian còn lại là tự nghiên cứu. Các học viên sau khi tốt nghiệp đại học sẽ\n",
      "text generated: được tuyển dụng làm việc tại một công ty trường cao đẳng với sự hỗ trợ của trường chương trình đào tạo\n"
     ]
    }
   ],
   "source": [
    "generate(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
